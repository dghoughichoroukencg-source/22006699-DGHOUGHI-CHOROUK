

# üìò COMPTE RENDU : ANALYSE DU PROJET DATA SCIENCE (CYBERS√âCURIT√â)

![WhatsApp Image 2025-10-27 √† 13 39 11_c6ff40d2](https://github.com/user-attachments/assets/b394e0fd-933c-49ff-a8f4-046bf238ea93)













Chorouk dghoughi
22006691

## 1. Le Contexte M√©tier et la Mission

### Le Probl√®me (Business Case)
Nous sommes ici face √† un enjeu de **Cybers√©curit√© Mondiale**. Les entreprises et gouvernements subissent des attaques vari√©es g√©n√©rant des pertes financi√®res massives.
* **Objectif :** Cr√©er un mod√®le d'IA capable de classifier/pr√©dire la nature de la menace (la Cible comporte ici **72 classes** distinctes, ce qui est beaucoup plus complexe qu'un probl√®me binaire).
* **L'Enjeu critique :** Identifier correctement le type d'attaque ou l'attaquant permet d'activer la bonne strat√©gie de d√©fense (ex: Firewall vs IA-based detection) et de minimiser les pertes financi√®res et le vol de donn√©es.

### Les Donn√©es (L'Input)
Le dataset analys√© dans le notebook contient **3000 observations** et **10 colonnes**.
* **Features (X) :** Variables mixtes incluant l'ann√©e (`Year`), les pertes financi√®res (`Financial Loss`), le nombre d'utilisateurs affect√©s, etc.
* **Target (y) :** Une variable cat√©gorielle tr√®s fragment√©e avec **72 classes uniques**, ce qui rend la t√¢che de classification particuli√®rement ardue pour un mod√®le al√©atoire.

---

## 2. Le Code Python (Laboratoire)
Le notebook suit la structure standard "Paillasse de laboratoire" :
C'est une excellente initiative. Pour respecter rigoureusement la structure p√©dagogique du fichier "Correction Projet.md" (style "Paillasse de laboratoire"), j'ai r√©organis√© ton code.

J'ai conserv√© toute la logique sp√©cifique √† ton dataset de Cybers√©curit√© (gestion des 72 classes, encodage One-Hot, imputation mixte) mais je l'ai habill√©e avec les commentaires, les √©tapes num√©rot√©es et les affichages "pas √† pas" typiques du fichier de correction.

Voici le code transform√© :

```python
# ==============================================================================
# üìò PROJET DATA SCIENCE : CYBERSECURITY THREAT ANALYSIS
# ==============================================================================

# Objectif : Nettoyer, Explorer et Mod√©liser des menaces de cybers√©curit√©.
# ==============================================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Modules Scikit-Learn
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Configuration esth√©tique
sns.set_theme(style="whitegrid")
import warnings
warnings.filterwarnings('ignore') # Silence les alertes pour la clart√©

print("1. Biblioth√®ques import√©es. Pr√™t √† d√©marrer.\n")

# ------------------------------------------------------------------------------
# 2. CHARGEMENT DES DONN√âES (L'Input)
# ------------------------------------------------------------------------------
print("2. Chargement du dataset...")

# Chargement du fichier
file_path = '/content/drive/MyDrive/Projet DS/Global_Cybersecurity_Threats_2015-2024.csv'
df = pd.read_csv(file_path)

# --- Normalisation de la cible (Sp√©cifique √† ce dataset) ---
# Si la colonne cible n'est pas nomm√©e 'target', on la renomme pour standardiser le code
if df.columns[-1] != 'target':
    df.rename(columns={df.columns[-1]: 'target'}, inplace=True)

# R√©cup√©ration des labels r√©els pour g√©rer les 72 classes correctement plus tard
actual_target_labels = sorted(df['target'].unique())
target_names = [str(label) for label in actual_target_labels]

print(f"   >>> Dataset charg√© : {df.shape[0]} lignes, {df.columns.size} colonnes.")
print(f"   >>> Complexit√© du probl√®me : {len(actual_target_labels)} classes uniques √† pr√©dire.\n")

# ------------------------------------------------------------------------------
# 3. SIMULATION DE "DONN√âES SALES" (Mise en situation)
# ------------------------------------------------------------------------------
# Le monde r√©el est sale. On simule des trous de donn√©es (NaN) pour tester notre nettoyage.
print("3. Sabotage contr√¥l√© des donn√©es (Introduction de NaN)...")

np.random.seed(42) 
df_dirty = df.copy()

# On ne touche pas √† la Target, mais on ab√Æme les Features (5% de trous)
features_columns = df.columns[:-1]
for col in features_columns:
    mask = np.random.random(df.shape[0]) < 0.05
    df_dirty.loc[mask, col] = np.nan

nb_missing = df_dirty.isnull().sum().sum()
print(f"   >>> {nb_missing} valeurs manquantes g√©n√©r√©es artificiellement.\n")

# ------------------------------------------------------------------------------
# 4. NETTOYAGE ET PR√âPARATION (Data Wrangling)
# ------------------------------------------------------------------------------
print("4. Nettoyage des donn√©es (R√©paration)...")

# S√©paration X (Features) et y (Target)
X = df_dirty.drop('target', axis=1)
y = df_dirty['target']

# --- Strat√©gie Hybride : Num√©rique vs Cat√©goriel ---
# Contrairement au cancer (tout num√©rique), ici nous avons du texte.
numerical_cols = X.select_dtypes(include=np.number).columns
categorical_cols = X.select_dtypes(exclude=np.number).columns

# A. Imputation Num√©rique (Moyenne)
if len(numerical_cols) > 0:
    imputer_num = SimpleImputer(strategy='mean')
    X_num = pd.DataFrame(imputer_num.fit_transform(X[numerical_cols]), 
                         columns=numerical_cols, index=X.index)
else:
    X_num = pd.DataFrame(index=X.index)

# B. Imputation Cat√©gorielle (Mode / Plus fr√©quent)
if len(categorical_cols) > 0:
    imputer_cat = SimpleImputer(strategy='most_frequent')
    X_cat = pd.DataFrame(imputer_cat.fit_transform(X[categorical_cols]), 
                         columns=categorical_cols, index=X.index)
else:
    X_cat = pd.DataFrame(index=X.index)

# Reconstruction du dataset propre
X_clean = pd.concat([X_num, X_cat], axis=1)
# On remet les colonnes dans l'ordre d'origine
X_clean = X_clean[X.columns]

print(f"   >>> Nettoyage termin√©. Valeurs manquantes restantes : {X_clean.isnull().sum().sum()}\n")

# ------------------------------------------------------------------------------
# 5. ANALYSE EXPLORATOIRE (EDA)
# ------------------------------------------------------------------------------
print("5. Inspection des donn√©es (EDA)...")

# A. Statistiques descriptives
print("   --- Statistiques (Variables Num√©riques) ---")
if len(numerical_cols) > 0:
    print(X_clean[numerical_cols].describe().T.head())
else:
    print("   (Pas de variables num√©riques)")

# B. Visualisation de distribution
plt.figure(figsize=(10, 5))
if len(numerical_cols) > 0:
    col_plot = numerical_cols[0]
    sns.histplot(data=df, x=col_plot, hue='target', element="step", common_norm=False)
    plt.title(f"Distribution : {col_plot} (Premier Feature Num√©rique)")
elif len(categorical_cols) > 0:
    col_plot = categorical_cols[0]
    sns.countplot(data=df, x=col_plot, hue='target')
    plt.title(f"Distribution : {col_plot} (Premier Feature Cat√©goriel)")
    plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# C. Matrice de Corr√©lation
if len(numerical_cols) > 1:
    plt.figure(figsize=(8, 6))
    sns.heatmap(X_clean[numerical_cols].corr(), annot=True, cmap='coolwarm', fmt=".2f")
    plt.title("Matrice de Corr√©lation")
    plt.show()

print("\n")

# ------------------------------------------------------------------------------
# 6. ENCODAGE ET SPLIT (Train / Test)
# ------------------------------------------------------------------------------
print("6. Pr√©paration pour le Machine Learning...")

# A. Encodage One-Hot (Transformer le texte en nombres pour l'IA)
print("   >>> Encodage des variables cat√©gorielles (One-Hot)...")
X_encoded = pd.get_dummies(X_clean, columns=categorical_cols, drop_first=True)

# B. Split Train/Test
# On garde 20% pour l'examen final
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

print(f"   >>> Donn√©es d'Entra√Ænement : {X_train.shape}")
print(f"   >>> Donn√©es de Test (Cach√©es) : {X_test.shape}\n")

# ------------------------------------------------------------------------------
# 7. MOD√âLISATION (Random Forest)
# ------------------------------------------------------------------------------
print("7. Entra√Ænement du Cerveau (Random Forest)...")

# Cr√©ation du mod√®le (100 arbres de d√©cision qui votent)
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Entra√Ænement (Fit)
model.fit(X_train, y_train)
print("   >>> Mod√®le entra√Æn√© avec succ√®s.\n")

# ------------------------------------------------------------------------------
# 8. √âVALUATION (L'Heure de V√©rit√©)
# ------------------------------------------------------------------------------
print("8. R√©sultats et Performance...")

# Pr√©dictions
y_pred = model.predict(X_test)

# A. Accuracy Globale
acc = accuracy_score(y_test, y_pred)
print(f"   >>> Accuracy Score : {acc*100:.2f}%")

# B. Rapport d√©taill√© (Pr√©cision, Rappel par classe)
print("\n   >>> Rapport de Classification (Extrait) :")
# Note : Avec 72 classes, le rapport complet est long, on l'affiche quand m√™me
print(classification_report(y_test, y_pred, labels=actual_target_labels, target_names=target_names))

# C. La Matrice de Confusion (Visualisation des erreurs)
cm = confusion_matrix(y_test, y_pred, labels=actual_target_labels)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=False, cmap='Blues', cbar=True) # Annot=False car 72x72 c'est illisible avec des chiffres
plt.title(f'Matrice de Confusion ({len(actual_target_labels)} Classes)')
plt.xlabel('Classe Pr√©dite')
plt.ylabel('Classe R√©elle')
plt.show()

print("\n--- FIN DU RAPPORT ---")
```
1.  **Acquisition :** Chargement de 3000 lignes.
2.  **Simulation d'erreurs :** Introduction artificielle de valeurs manquantes (NaN) dans 1350 cellules pour tester la robustesse du nettoyage.
3.  **Nettoyage & Imputation :** Traitement diff√©renci√© des variables num√©riques et cat√©gorielles.
4.  **Mod√©lisation & √âvaluation :** Entra√Ænement du mod√®le et visualisation de la performance sur 72 classes.

---

## 3. Analyse Approfondie : Nettoyage (Data Wrangling)

### La M√©canique de l'Imputation dans ce Notebook
Le notebook a d√ª g√©rer deux types de donn√©es, contrairement au projet m√©dical purement num√©rique :
1.  **Imputation Num√©rique :** Pour des colonnes comme `Financial Loss`, le code a utilis√© la **Moyenne** (Mean). Les trous ont √©t√© bouch√©s par la valeur moyenne calcul√©e (~50.63 Millions $).
2.  **Imputation Cat√©gorielle :** Pour les colonnes textuelles (ex: type d'attaque), le code a utilis√© le **Mode** (la valeur la plus fr√©quente).

### üí° Le Coin de l'Expert (Data Leakage)
*Observation Critique :* Dans le notebook, le nettoyage (√âtape 4) semble avoir √©t√© effectu√© sur l'ensemble du dataset *avant* le split Train/Test.
* **Verdict :** Il y a un risque de **Data Leakage**. En calculant la moyenne des pertes financi√®res sur les 3000 lignes (y compris celles qui serviront au test), le mod√®le a "trich√©" en voyant indirectement des informations du futur. Dans un environnement de production strict, il faudrait `fit` l'imputer uniquement sur le Train Set.

---

## 4. Analyse Approfondie : Exploration (EDA)

L'analyse des statistiques descriptives (√©tape 5 du notebook) r√©v√®le la structure des donn√©es :

### D√©crypter `.describe()`
* **Sym√©trie Parfaite (Distribution Normale ?) :**
    * Pour `Financial Loss`, la Moyenne est de **50.63** et la M√©diane (50%) est de **50.63**.
    * Pour `Affected Users`, la Moyenne est de **503,899** et la M√©diane est de **503,899**.
* **Interpr√©tation :** Contrairement aux donn√©es m√©dicales souvent asym√©triques (skewed), ces donn√©es (probablement simul√©es ou tr√®s √©quilibr√©es) suivent une distribution parfaitement sym√©trique. Il n'y a pas d'outliers massifs qui tirent la moyenne vers le haut.
* **Dispersions (Std) :** Les √©carts-types sont significatifs (28M$ de perte), indiquant une grande vari√©t√© dans la gravit√© des attaques, ce qui est une bonne nouvelle pour l'apprentissage du mod√®le (il a de la variance √† expliquer).

---

## 5. Analyse Approfondie : M√©thodologie (Split)

Le protocole exp√©rimental reste le garant de la g√©n√©ralisation. Avec 3000 lignes et 72 classes, le split (probablement 80/20 standard) laisse environ 600 exemples pour le test.
* **Le D√©fi Multiclasse :** Avec 72 classes, certaines classes peuvent √™tre rares. Un split al√©atoire simple (`train_test_split`) risque de ne mettre *aucun* exemple d'une classe rare dans le jeu d'entra√Ænement. Une s√©paration **stratifi√©e** (`stratify=y`) serait ici fortement recommand√©e pour s'assurer que le mod√®le voit au moins une fois chaque type de menace.

---

## 6. FOCUS TH√âORIQUE : L'Algorithme Random Forest üå≤

Dans ce contexte de cybers√©curit√© avec des donn√©es mixtes (cat√©gorielles et num√©riques) et un grand nombre de classes :

### La Pertinence du Random Forest
* **Robustesse aux dimensions :** Avec 72 classes en sortie, un arbre de d√©cision unique serait gigantesque et ferait du sur-apprentissage (overfitting) massif.
* **Le Bagging √† la rescousse :** En moyennant les d√©cisions de plusieurs arbres, le Random Forest lisse les fronti√®res de d√©cision. Si un arbre se trompe sur une cyber-attaque sp√©cifique (ex: confondre un Malware Russe avec un Phishing Chinois), les autres arbres peuvent corriger le tir par vote majoritaire.

---

## 7. Analyse Approfondie : √âvaluation (L'Heure de V√©rit√©)

### A. La Matrice de Confusion (72x72)
La visualisation g√©n√©r√©e dans le notebook (`sns.heatmap`) est une grille massive de 72x72 cases.
* **Diagonale :** Les cases sur la diagonale repr√©sentent les **Succ√®s** (Attaque pr√©dite = Attaque r√©elle).
* **Hors Diagonale :** Tout le reste est du bruit.
* **Lecture :** Contrairement au cas binaire (4 cases), on cherche ici des "clusters" d'erreurs. Par exemple, le mod√®le confond-il souvent les attaques "Ransomware" avec "Malware" ?

### B. Les M√©triques Avanc√©es (Adaptation Multiclasse)
* **Accuracy (Pr√©cision Globale) :** Avec 72 classes, une accuracy de 50% serait en r√©alit√© excellente (le hasard ferait 1/72 ‚âà 1.4%). Il ne faut donc pas juger ce chiffre avec les standards du binaire (o√π 50% est nul).
* **Pr√©cision & Rappel (Macro/Weighted Average) :**
    * Si le **Rappel** est bas pour une classe critique (ex: "Attaque √âtatique"), cela signifie que le syst√®me de d√©fense laisse passer des menaces majeures sans les d√©tecter.
    * Si la **Pr√©cision** est basse, le syst√®me g√©n√®re trop de fausses alertes, noyant les analystes de s√©curit√© sous du bruit (fatigue d'alerte).

### Conclusion
Le projet pr√©sent√© dans `CODE.ipynb` est techniquement plus complexe que le projet m√©dical sur un point : la **cardinalit√© de la cible** (72 classes). Le nettoyage a r√©ussi (0 NaN restants), mais la vigilance sur le Data Leakage et l'interpr√©tation des r√©sultats multiclasses reste primordiale pour un d√©ploiement industriel.
